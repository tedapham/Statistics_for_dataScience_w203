---
title: "Untitled"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---
title: "HW week 10"
subtitle: "w203: Statistics for Data Science"
output: pdf_document
author: "Ted Pham"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. Recall that the slope coefficient in a simple regression of $Y_i$ on $X_i$ can be expressed as,

$$ \beta_1 = \frac{\hat{cov}(X_i, Y_i)}{\hat{var}(X_i)}$$

Suppose that you were to add a random variable, $M_i$, representing measurement error, to each $X_i$.  You may assume that $M_i$ is uncorrelated with both $X_i$ and $Y_i$.  You then run a regression of $Y_i$ on $X_i + M_i$ instead of on $X_i$.  Does the measurement error increase or decrease your slope coefficient?


$$
\beta_1 = \frac{\hat{cov}(X_i+M_i,Y_i)}{\hat{var}(X_i+M_i)}=\frac{\hat{cov}(X_i,Y_i) + \hat{cov}(M_i,Y_i)}{Var(X_i)+Var(M_i)+2\hat{cov}(M_i,X_i)}
$$
Since $M_i$ is uncorrelated with both $X_i$, $Y_i$, 

$$\hat{cov}(M_i,Y_i) = \hat{cov}(M_i,X_i) =0
$$


$$ 

\beta_1 = \frac{\hat{cov}(X_i,Y_i)}{Var(X_i)+Var(M_i)}
$$

The slope coefficient will decrease.


---


The file bwght.RData contains data from the 1988 National Health Interview Survey.  It was used by J Mullahy for a 1997 paper (“Instrumental-Variable Estimation of Count Data Models:  Applications to Models of Cigarette Smoking Behavior,” Review of Economics and Statistics 79, 596-593.) and provide by Wooldridge.  You will use this data to examine the relationship between cigarette smoking and a child's birthweight.

```{r}
load("bwght.RData")
ls()
```

1. Examine the dependent variable, infant birth weight in ounces (bwght) and the independent variable, the number of cigarettes smoked by the mother each day during pregnacy (cigs).

```{r}
names(data)
names(desc)
bwght = data$bwght
cigs = data$cigs
which(is.na(bwght))
which(is.na(cigs))
```
```{r}
summary(bwght)
summary(cigs)
plot(cigs,bwght)
plot(as.factor(cigs),bwght)

```
2. Fit a linear model that predicts bwght as a function of cigs.  Superimpose your regression line on a scatterplot of your variables.
```{r}
fit = lm(bwght ~ cigs)
plot(cigs, bwght)
abline(fit,col='red',lwd=3)
```
3. Examine the coefficients of your fitted model.  Explain, in particular, how to interpret the slope coefficient on cigs.  Is it practically significant?
```{r}
coef(fit)
```
4. Write down the two moment conditions for this regression.  Use R to verify that they hold for your fitted model.

The var(u) = 0 and sum(X*u)=0


```{r}
bwght_hat = bwght
bwght_hat = -0.5137721*cigs + 119.7719
print(sum(bwght_hat-bwght))
print(sum((bwght_hat-bwght)*cigs))
```

5. Does this simple regression capture a causal relationship between smoking and birthweight?  Explain why or why not.
No only 2.2% of variability in birthweight is captured by the variability in
```{r}
summary(fit)$r.squared
```
6. Does your scatterplot show evidence of measurement error in cigs?  If so, what does this say about the true relationship between cigarettes and birthweight?
The cigs variables skip values between 20 and 50. The number of cigs increase by 10 for every step. This might be an error in measurement.
The birthweight and cigs might have a strong linear relationship without the error.


7. Using your coefficients, what is the predicted birthweight when cigs is 0?  When cigs is 20?
```{r}
y_0 = 119.772
y_1 = -0.514*20 + 119.772
y_0
y_1
```
8. Use R's predict function to verify your previous answers.  You may insert your linear model object into the command below.

```{r eval = FALSE}
predict(fit, data.frame(cigs = c(0, 20) ) )
```

9. To predict a birthweight of 100 ounces, what would cigs have to be?
?
```{r}
(100-119.772)/(-0.514)
```
